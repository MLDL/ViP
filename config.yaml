acc_metric:      Accuracy              # Accuracy metric 
batch_size:      10                    # Numbers of videos in a mini-batch 
clip_length:     16                    # Number of frames within a clip 
clip_offset:     0                     # Frame offset between beginning of video and clip (1st clip only) 
clip_stride:     0                     # Frame offset between successive frames
crop_shape:      [112,112]             # (Height, Width) of frame  
crop_type:       Random                # Type of cropping operation (Random, Central and None)  
dataset:         HMDB51                # Name of dataset 
epoch:           30                    # Total number of epochs 
exp:             exp                   # Experiment name
final_shape:     [112,112]             # (Height, Width) of input to be given to CNN
gamma:           0.1                   # Multiplier with which to change learning rate
json_path:       /z/dat/HMDB51/        # Path to the json file for the given dataset
labels:          51                    # Number of total classes in the dataset
load_type:       train                 # Environment selection, to include only training/training and validation/testing dataset
loss_type:       M_XENTROPY            # Loss function
lr:              0.0001                # Learning rate
milestones:      [10, 20]              # Epoch values to change learning rate     
model:           C3D                   # Name of model to be loaded  
momentum:        0.9                   # Momentum value in optimizer
num_clips:       -1                    # Number clips to be generated from a video (<0: uniform sampling, 0: Divide entire video into clips, >0: Defines number of clips) 
num_workers:     2                     # Number of CPU worker used to load data
opt:             sgd                   # Name of optimizer
preprocess:      default               # String argument to select preprocessing type
pretrained:      1                     # Load pretrained network 
random_offset:   0                     # Boolean switch to generate a clip length sized clip from a video 
rerun:           1                     # Number of trials to repeat an experiment
resize_shape:    [128,171]             # (Height, Width) to resize original data 
sample_duration: 16                    # Temporal size of video to be provided as input to the model 
sample_size:     112                   # Height of frame to be provided as input to the model
save_dir:        './results'           # Path to results directory
seed:            999                   # Seed for reproducibility 
subtract_mean:   ''                    # Subtract mean (R,G,B) from all frames during preprocessing
verbose:         1                     # Print status updates during runtime (1 true, 0 false)
weight_decay:    0.0005                # Weight decay
